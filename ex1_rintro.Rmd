---
title: "DEM 7283 - Example 1 - Introduction to R and review of Stat 1"
author: "Corey Sparks, PhD"
date: "January 9, 2017"
---

Welcome to R. R is pretty similar to stata. R and stata are both interpreted languages, not a compiled one. This means, you type something into R and it does it. There is no data step. There are no procs. The SAS and R book is very useful for going between the two programs.  

R uses libraries to do different types of analysis, so we will need to install lots of different libraries to do different things. These need to be downloaded from the internet, using the `install.packages()` command. You only need to install a package once. E.g.

`install.packages("lme4")`
will install the lme4 library. To use the functions within it, type

`library(lme4)`

Now you have access to those fuctions. 

Below we will go through a simple R session where we basically review much of the concepts from DEM 7273. We will load a dataset, print some cases, do some descriptice statistics and plots, t tests, and some linear models and diagnostics of those models.

```{r, message=FALSE}
#Load some libraries that I need, you will need to install these first in order to use them
library(lmtest)
library (car)
library(Hmisc)
library(sandwich)
library(multcomp)
library(knitr)
library(lattice)
```


Read in a Commma separated values file, In this case, I am using the Population Reference Bureau's Population Data sheet from 2008.
Here, I call my R object `dat`, I could call it pretty much anything I want though.

R creates objects through the assignment operator `<-`

```{r}
dat<-read.csv("https://raw.githubusercontent.com/coreysparks/data/master/PRB2008_All.csv", header=T)

#print all of the variable names in the data set
names(dat)

#look at the first 5 cases
head(dat, n=5)
```


Let's have a look at some descriptive information about the data:
```{r}
#Frequency Table of # of Contries by Continent
table(dat$Continent)


#basic summary statistics for the variable TFR or the total fertility rate
summary(dat$TFR)

```

We see the mean is `r mean(dat$TFR, na.rm=T)` and that `r as.numeric(table(is.na(dat$TFR))[2])` case is missing. That case is `r as.character(dat$Country[which(is.na(dat$TFR))])`. 

##More Descriptive statistics

```{r}
#just want a mean
mean(dat$TFR, na.rm=T)

#what does R give if there's a missing case and I don't specify na.rm=T?
mean(dat$TFR)

```

NA means something is missing. NA is used for all kinds of missing data. So in this case, R won't compute the mean because one case is missing, so it contributes no informaiton to the estimation of the mean.

```{r}
#standard deviation
sd(dat$TFR, na.rm=T)

#Quantiles
quantile(dat$TFR, na.rm=T)
```

The median is `r quantile(dat$TFR, na.rm=T,.5)`

```{r}
#histogram of the infant mortality rate
hist(dat$TFR, main="Histogram of Total Fertility Rate")

#Box plot for TFR* Continent
bwplot(TFR~Continent, dat,main="Boxplot of Total Fertility Rate by continent")

#scatter plot of TFR * IMR, the infant mortality rate
xyplot(TFR~IMR, data=dat, main="Bivariate Association between TFR and IMR")


```


##T-tests
If our outcome is continuous and approximately normal, then we can use a t-test to compare the mean of two groups.
```{r}
#t-test for Africa vs Rest of the world
#Useing the I() funciton, which generates a T/F value, i.e. 2 groups, Africa or Not Africa
t.test(TFR~I(Continent=="Africa"), dat, var.equal=F)

```

Which shows the mean TFR for Africa is 4.77 and the mean of the rest of the world is 2.39. The test is highly significant (big t value, low p value), suggesting the means are not equal.


Let's illustrate this with a box and whisker plot.

```{r}
dat$Africa<-Recode(dat$Continent, recodes =' "Africa"="Africa"; else="notAfrica"', as.factor = T)
#BE SURE TO SPECIFY YOUR COMPARISON LEVEL!!! OTHERWISE R WILL TAKE THE FIRST ALPHANUMERIC VALUE!!!!
dat$Africa<-relevel(dat$Africa, ref = "notAfrica")
bwplot(TFR~Africa, data=dat)
```
Which shows the differences very clearly, but also the differences in variability, with Africa being much more variable overall.

###Linear model for a t-test
I have thrown away the t-test per se and have moved purely to the linear model for all two and multiple group testing (the multi group case is already the linear model!). For the two group case, the linear model is:

$TFR_i = \alpha + \beta * Africa_i + e_i$

Where $\beta$ tells us how much the mean shifts up or down for countries in Africa, on average. All non African countries have the Africa variable == 0, so thier estimated mean is just $\alpha$.

```{r}
#Simple ANOVA model version of a t-test
fit<-lm(TFR~Africa, dat)
summary(fit)
anova(fit)
```

The `(Intercept)` Estimate is 2.39, which we have already seen is the mean TFR for non-African countries. The Estimate for `Africa1Africa` is 2.38, which tells us the mean for Africa is 2.38 TFR points higher than non-African countries, on average. The estimate for this parameter is large, relative to its error and the t-statisitic is also large, suggesting the estimate is good, the p-value for the test is small, giving good evidence that the parameter is not 0, or that the means are not equal.


###ANOVA model for IMR by continent
The ANOVA model is also easily fit:
```{r}
fit<-lm(IMR~Continent, dat)
anova(fit)

#Post hoc tests using Bonferroni comparisons
pairwise.t.test(dat$TFR,dat$Continent,p.adjust.method = "bonf")



```



###Basic OLS Multiple regression models
```{r}
#fit the basic regression model
fit1<-lm(TFR~ IMR + log(GNIPPPperCapitaUSDollars)+ log(PopDensPerSqMile), data=dat)
summary(fit1)
#do some diagnostic plots
plot(fit1)

```

###Assess the assumptions of the model:

```{r}
#Normality of residuals from the first fit?
shapiro.test(rstudent(fit1))
plot(density(rstudent(fit1)))

```

The test shows non normality, but the density plot looks pretty normal. The Shapiro Wilk test is known to be overly sensitive.


Other assumptions of the model:
```{r}
#test for heteroskedasticity
bptest(fit1)

```
We see evidence of heteroskedasticity, which can affect our standard errors for our hypothesis tests. We can use the White correction for heteroskedasticty:

```{r}
#make White-corrected t-statistics and p values
coeftest(fit1, vcov=vcovHC(fit1, type = "HC0"))
```

Which is very similar to that from above assuming constant variances. The std. errors for IMR and GDP are a little higher, but nothing substantively different.


```{r}
#variance inflation factors
vif(fit1)
```


###More complicated linear models:

Here is the ANCOVA model for testing equality of slopes between groups:
```{r}
#now we fit a model that includes differences between continents
fit2<-lm(TFR~ IMR+ log(GNIPPPperCapitaUSDollars)+ log(PopDensPerSqMile)+ Continent, data=dat)
summary(fit2)

#We can compare how model 2 performs compared to model 1 by using an F test
anova (fit1, fit2, test="F")


#Now we fit a model with an interaction term between continent and GDP, in R this is easy, all we have to do is use the * operation
fit3<-lm(TFR~ IMR + log(GNIPPPperCapitaUSDollars)+ log(PopDensPerSqMile) + Continent*log(GNIPPPperCapitaUSDollars), data=dat)
summary(fit3)

#We can compare out model 2 with the interaction model to see if there is a significant difference in how GDP operates across continents
anova (fit2, fit3, test="F")
```

This test suggests that there is ha significant interaction between GDP and Continent

###Transformations of outcomes
Sometimes to coax residuals into normality or constant variance, we can try a transformation, such as a log or square root, here we examine a log transformed outcome, this can be easily done within the lm() function
```{r}

fit4<-lm(log(TFR) ~ IMR + log(GNIPPPperCapitaUSDollars)+ log(PopDensPerSqMile)+Continent, data=dat)
summary(fit4)

#Normality of errors
shapiro.test(rstudent(fit4))
#Heterosckedasticity test
bptest(fit4)

```
We still see the model has problems with heteroskedasticity.

###Output of results

Here we make a nice table of the results between the model using the transformed outcome and that which used the un-transformed outcome.

```{r , results='asis'}
library(stargazer)

stargazer(fit2, fit4, title="Model results from untransformed and log transformed outcome",type="html", align=T, covariate.labels = c("TFR", "lnGDP", "lnDens"))

```

We can also make a table comparing the nested models:
```{r, results="asis"}
stargazer(fit2, fit3, title="Model results from nested models",type="html", align=T, covariate.labels = c("TFR", "lnGDP", "lnDens"))

```

